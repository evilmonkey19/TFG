\section{Live-streaming state of art }

{
    Live-streaming content is in its dawn. Although it is possible and it is being done nowadays, real-time content in Internet is still primitive
    in the way we are delivering it. We are using brute-force to deliver huge amounts of real-time content. It is a matter of fact that 
    the demand for this type of content is growing far faster than the CDN \footnote{CDN: Content Delivery Network} (from now on called servers)
    are able to supply to the spectactors (from now on called clients).
    
    Even though someone might say it is almost every content via internet, there are still a lot of events that can not transmitted using internet 
    because it cannot be supported\footnote{https://github.com/GrumpyOldTroll/wicg-multicast-receiver-api/blob/master/explainer.md} due to the heavy load
    of users that need to managed. As Jake Holland from Akamai wrote on Github: "The capacity of CDNs and others to deliver popular content at scale is 
    not keeping up with demand."

    In april of 2020, Akamai achieved the new world record of peak traffic delivery which was 176 tbps. It seems a lot, however it is not. Making some linear
    and quick easy maths it is easy to see that it is not. Keeping in mind that usually for real-time video we use CBR\footnote{Constant Bit-Rate} encoder in
    order to squeeze the internet resources, for a 1080p video we need a bit-rate of 5 mbps, and for a 4k video, 20 mbps. This means that with the current
    world-record we can arrive to 35.2 millions of simultaneous users for live-streaming content using a 1080p encoding and 8.8 millions users using 4k.
    Considering that the world population with internet access is 5200 million people we are really faraway from delivering TV or Radio via Internet using
    the current methods. What is more, the Fifa World Cup Finals 2018 were seen by 500 million people, 200 million to 300 million people were seeing in India the Cricket
    World Cup in 2015 (whenever India is playing) and a large etcetera with a lot of content can be done.  The brute force does not seem like a good stategy for scaling 
    anymore, maybe only for quick deployments.

    The solution that is being discussed in this Final Degree Project proposes to use multicast instead of unicast in order to avoid this scalability limitation, due to
    the fact that using this technology for distribute the same content to everyone is more efficient in terms of computation in the servers and of resources in general.
}

\subsection{Technologies used at the moment}
{
    TCP is at the moment the main protocol over Internet. Almost every service at the moment uses it and HTTP is not an exception. When doing a HTTP request or response (versions 1.0,
    1.1 and 2), TCP is being used. Even though, it is almost 50 years old and the internet has evolved and has grown significantly, it is still the main protocol. However, it is reaching
    its full capacity in two particular scenarios: websites with small pageload and real-time content such as TV and Radio. Although, the main goal of this project is to focus on the 
    real-time content delivery, the small pageload problem will also be explained briefly because is what QUIC tries to solve as originally planned.    
    
    Most of the is requested via a navigator like Firefox or Google Chrome, which use the HTTP protocol as the main communication protocol which the use of TCP. It is clear and obvious
    that for large content which is not in real-time that can be stored like films, TCP is not a big bottleneck. However, in the last several years, with the
    raising of important services (like e-commerce) and cyberattacks, specially spoofing, the use of TLS\footnote{TLS : Transport Security Layer} has also became a standard. Websites that
    deliver real-time video like Youtube or Twitch are not an exception either. This also adds some complexity and workload delivering the website to the client.

    When someone connects to a internet using a web-browser at least it need 3 packets for for stablishing the TCP connection, 3 for stablishing the TLS connection over TCP and 2 HTTP packets (request and response).
    It is being received the first byte of content after the 7th packet! This handshake, although being the most being used, it is not optimal. When a really small website is being delivered (imagine an html "Hello World!"),
    a load of resources and packets are being used for a deliver a small packet. More control stuff than content. It gets even worse, if it is the case that have already stablished a connection earlier and after a while there
    is a new request; all this handshake has to be done again because TCP and TLS are a connection oriented protocols, but HTTP is not. QUIC aims to solve this type of problems.
}
\subsection{The new standard: QUIC}
{
    
    It is clear and obvious that for large content that can be stored in a small buffer and does not need to be real-time we can use a really known 
    protocol that have been around for years which is TCP. It is the main protocol for most of the services in the internet and has been even implemented
    in the kernel of most of the devices. Many of the devices that rule internet like firewalls or load-balancers were designed bearing in mind that the
    protocol that had to be used was TCP. During many years it was not a priority to use other transport layer protocols except in rare case.

    Nowadays, might be surprising that we use that procotol that is end-to-end to deliver the same real-time content to a large amount of spectactors (for
    now on they will be called clients)\footnote{In the Annexe I there is a larger explanation and details on how to test this with famous websites at the
    moment}. It is easy to see that this approach although having many withdrawals it has some benefits.

    The solution that is being discussed in this Final Degree Project proposes to use multicast instead of unicast in order to avoid this scalability limitation, due to
    the fact that using this technology for distribute the same content to everyone is more efficient in terms of computation in the servers and of resources in general.
}

\subsection{Benefits of using TCP for live-streaming}
{
    The main benefit with this approach for real-time content is the easiness on the programming and mounting at first time. All devices (or almost all) can
    bypass internet elements when they talk TCP. 
 
    
    At the current moment, it is the standard which means less complexity, more tools and easier to implement. For
    young services that are not expected to growth a lot TCP is more than enought for most cases.

    At the same time, there 
}

\subsection{UDP}{
    
    Nevertheless, in the last decade it has been a growing interest in other procotols that are end-to-end and allow to expand functionalities in upper layers:
    UDP\footnote{UDP: User Datagram Protocol}. It is a really simple protocol with almost 0 functionalities aside from passing the content to the upper layer.
    It has been around since the creation of the internet. That means, like with TCP, is implemented in the kernel. Changing the kernel of all the devices in
    the internet it is imposible 
}

\subsection{Topic}

Here you have a couple of references about LaTeX ~\cite{latexcompanion} and electrodynamics \cite{einstein}.

\bigskip

\subsection{Topic}
